{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26209d52",
   "metadata": {},
   "source": [
    "# 04 – Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae19d4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (19051, 108)\n"
     ]
    }
   ],
   "source": [
    "# Import all required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "import xgboost as xgb\n",
    "import joblib\n",
    "\n",
    "# Load processed data\n",
    "df = pd.read_csv(\"../data/processed/cleaned_data.csv\")\n",
    "print(f\"Dataset shape: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a2950189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set: (15240, 107), Test set: (3811, 107)\n"
     ]
    }
   ],
   "source": [
    "# Prepare features and target\n",
    "X = df.drop(\"price_lkr\", axis=1)\n",
    "y = df[\"price_lkr\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set: {X_train.shape}, Test set: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b32cee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../models/scaler.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scale features for models that need it\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Save scaler for later use\n",
    "joblib.dump(scaler, \"../models/scaler.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9be96fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models to evaluate: ['Linear Regression', 'Ridge', 'Lasso', 'SVR', 'Random Forest', 'Gradient Boosting', 'XGBoost']\n"
     ]
    }
   ],
   "source": [
    "# Define all models to train\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge': Ridge(random_state=42),\n",
    "    'Lasso': Lasso(random_state=42),\n",
    "    'SVR': SVR(kernel='rbf'),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(random_state=42),\n",
    "    'XGBoost': xgb.XGBRegressor(random_state=42, verbosity=0)\n",
    "}\n",
    "\n",
    "print(\"Models to evaluate:\", list(models.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2481edd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training and evaluating models...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear Regression: R² = 0.9177 (+/- 0.0031)\n",
      "Ridge: R² = 0.9177 (+/- 0.0031)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\Desktop\\house-price-prediction-srilanka\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.244e+16, tolerance: 1.086e+14\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\DELL\\Desktop\\house-price-prediction-srilanka\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.364e+16, tolerance: 1.083e+14\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\DELL\\Desktop\\house-price-prediction-srilanka\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.253e+16, tolerance: 1.068e+14\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\DELL\\Desktop\\house-price-prediction-srilanka\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.142e+16, tolerance: 1.075e+14\n",
      "  model = cd_fast.enet_coordinate_descent(\n",
      "c:\\Users\\DELL\\Desktop\\house-price-prediction-srilanka\\venv\\Lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:716: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.298e+16, tolerance: 1.077e+14\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso: R² = 0.9177 (+/- 0.0031)\n",
      "SVR: R² = -0.0707 (+/- 0.0277)\n",
      "Random Forest: R² = 0.9458 (+/- 0.0033)\n",
      "Gradient Boosting: R² = 0.9431 (+/- 0.0033)\n",
      "XGBoost: R² = 0.9518 (+/- 0.0023)\n",
      "\n",
      "Best model: Random Forest with R² = 0.9458\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation with cross-validation\n",
    "print(\"Training and evaluating models...\")\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    try:\n",
    "        if name in ['Linear Regression', 'Ridge', 'Lasso', 'SVR']:\n",
    "            scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "        else:\n",
    "            scores = cross_val_score(model, X_train, y_train, cv=5, scoring='r2')\n",
    "\n",
    "        results[name] = scores.mean()\n",
    "        print(f\"{name}: R² = {scores.mean():.4f} (+/- {scores.std() * 2:.4f})\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error training {name}: {e}\")\n",
    "        results[name] = -float('inf')\n",
    "\n",
    "# Find best model (excluding XGBoost due to compatibility issues)\n",
    "best_model_name = max(results.items(), key=lambda x: x[1] if x[0] != 'XGBoost' else -float('inf'))[0]\n",
    "best_score = results[best_model_name]\n",
    "\n",
    "print(f\"\\nBest model: {best_model_name} with R² = {best_score:.4f}\")\n",
    "\n",
    "# Train the best model on full training data\n",
    "if best_model_name in ['Linear Regression', 'Ridge', 'Lasso', 'SVR']:\n",
    "    best_model = models[best_model_name]\n",
    "    best_model.fit(X_train_scaled, y_train)\n",
    "else:\n",
    "    best_model = models[best_model_name]\n",
    "    best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "19e6531b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing hyperparameter tuning for Random Forest...\n",
      "Best parameters: {'max_depth': None, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "Best CV score: 0.9463\n"
     ]
    }
   ],
   "source": [
    "if best_model_name == 'Random Forest':\n",
    "    print(\"Performing hyperparameter tuning for Random Forest...\")\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200, 300],\n",
    "        'max_depth': [10, 20, None],\n",
    "        'min_samples_split': [2, 5, 10]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(RandomForestRegressor(random_state=42), param_grid, cv=5, scoring='r2')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best CV score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "elif best_model_name == 'Gradient Boosting':\n",
    "    print(\"Performing hyperparameter tuning for Gradient Boosting...\")\n",
    "    param_grid = {\n",
    "        'n_estimators': [100, 200],\n",
    "        'max_depth': [3, 6],\n",
    "        'learning_rate': [0.1, 0.2]\n",
    "    }\n",
    "\n",
    "    grid_search = GridSearchCV(GradientBoostingRegressor(random_state=42), param_grid, cv=5, scoring='r2')\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_model = grid_search.best_estimator_\n",
    "    print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "    print(f\"Best CV score: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "else:\n",
    "    print(f\"Using default {best_model_name} model (no hyperparameter tuning needed)\")\n",
    "    best_model = models[best_model_name]\n",
    "    if best_model_name in ['Linear Regression', 'Ridge', 'Lasso', 'SVR']:\n",
    "        best_model.fit(X_train_scaled, y_train)\n",
    "    else:\n",
    "        best_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "590dfbcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model (Random Forest) saved as best_random_forest_model.pkl\n",
      "Scaler saved as scaler.pkl\n",
      "Feature names saved as feature_names.pkl\n",
      "\n",
      "Model training completed successfully!\n",
      "Best performing model: Random Forest\n",
      "Model saved to: models/best_random_forest_model.pkl\n"
     ]
    }
   ],
   "source": [
    "# Save the best model\n",
    "model_filename = f'best_{best_model_name.lower().replace(\" \", \"_\")}_model.pkl'\n",
    "joblib.dump(best_model, f'../models/{model_filename}')\n",
    "print(f\"Best model ({best_model_name}) saved as {model_filename}\")\n",
    "\n",
    "# Also save the scaler for preprocessing\n",
    "joblib.dump(scaler, '../models/scaler.pkl')\n",
    "print(\"Scaler saved as scaler.pkl\")\n",
    "\n",
    "# Save feature names for the web app\n",
    "feature_names = X.columns.tolist()\n",
    "joblib.dump(feature_names, '../models/feature_names.pkl')\n",
    "print(\"Feature names saved as feature_names.pkl\")\n",
    "\n",
    "print(\"\\nModel training completed successfully!\")\n",
    "print(f\"Best performing model: {best_model_name}\")\n",
    "print(f\"Model saved to: models/{model_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
